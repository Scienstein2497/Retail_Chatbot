{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56a1a02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import sqlite3\n",
    "import openai\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "import re\n",
    "import codecs\n",
    "import pandas as pd\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Establish a connection to the SQLite database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('retail_data.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define tables and columns based on the schema information\n",
    "\n",
    "# Tables in the retail_data.db database\n",
    "tables = [\n",
    "    \"BigSupplyCo_Orders\",\n",
    "    \"BigSupplyCo_Products\",\n",
    "    \"BigSupplyCo_Customers\",\n",
    "    \"BigSupplyCo_Departments\",\n",
    "    \"BigSupplyCo_Categories\"\n",
    "]\n",
    "\n",
    "# Columns in each table\n",
    "columns = {\n",
    "    \"BigSupplyCo_Orders\": [\n",
    "'order_id', 'order_item_cardprod_id', 'order_customer_id', 'order_department_id', 'market', 'order_city', 'order_country', 'order_region', 'order_state', 'order_status', 'order_zipcode', 'order_date__dateorders_', 'order_item_discount', 'order_item_discount_rate', 'order_item_id', 'order_item_quantity', 'sales', 'order_item_total', 'order_profit', 'type', 'days_for_shipping__real_', 'days_for_shipment__scheduled_', 'delivery_status', 'late_delivery_risk'       \n",
    "    ],\n",
    "    \"BigSupplyCo_Products\": ['product_card_id', 'product_category_id', 'product_description', 'product_image', 'product_name', 'product_price', 'product_status'\n",
    "\n",
    "    ],\n",
    "    \"BigSupplyCo_Customers\": [\n",
    "'customer_id', 'customer_city', 'customer_country', 'customer_email', 'customer_fname', 'customer_lname', 'customer_password', 'customer_segment', 'customer_state', 'customer_street', 'customer_zipcode'\n",
    "    ],\n",
    "    \"BigSupplyCo_Departments\": [\n",
    "        'department_id', 'department_name', 'latitude', 'longitude'\n",
    "    ],\n",
    "    \"BigSupplyCo_Categories\": [\n",
    "        'category_id', 'category_name'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'  # Replace 'your-api-key' with your actual API key\n",
    "\n",
    "def generate_ai_response(prompt, tables, columns):\n",
    "    try:\n",
    "        # Use OpenAI GPT-3.5 to generate a natural language response\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=150  # You can adjust the max_tokens based on the response length you need\n",
    "        )\n",
    "\n",
    "        # Get the generated response from OpenAI\n",
    "        generated_response = response.choices[0].text.strip()\n",
    "\n",
    "        # Tokenize user input\n",
    "        tokens = word_tokenize(prompt.lower())\n",
    "        # Check for keywords related to tables and columns\n",
    "        selected_table = None\n",
    "        selected_columns = []\n",
    "        for table in tables:\n",
    "            if table.lower() in tokens:\n",
    "                selected_table = table\n",
    "                selected_columns.extend(columns[table])\n",
    "\n",
    "        if selected_table:\n",
    "            # If a relevant table is found, construct the SQL query\n",
    "            sql_query = f\"SELECT {', '.join(selected_columns)} FROM {selected_table}\"\n",
    "            return generated_response, sql_query\n",
    "        else:\n",
    "            return generated_response, \"No relevant table found in the input.\"\n",
    "    except Exception as e:\n",
    "        return str(e), str(e)\n",
    "\n",
    "    \n",
    "# Function to create table from CSV file\n",
    "def create_table_from_csv(file_path, table_name, conn, encoding='utf-8'):\n",
    "    with codecs.open(file_path, 'r', encoding=encoding, errors='replace') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        headers = next(csvreader)  # Read headers from CSV\n",
    "        processed_headers = []\n",
    "        for header in headers:\n",
    "            # Replace spaces and special characters with underscores\n",
    "            processed_header = re.sub(r'\\W+', '_', header.lower())\n",
    "            processed_headers.append(processed_header)\n",
    "        headers_str = ', '.join(processed_headers)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} ({headers_str})\")\n",
    "        # Insert data from CSV into the table (assuming CSV format matches the table structure)\n",
    "        for row in csvreader:\n",
    "            cur.execute(f\"INSERT INTO {table_name} VALUES ({','.join(['?']*len(row))})\", row)\n",
    "\n",
    "# File paths for the CSV data\n",
    "departments_file = r'C:\\Users\\shara\\Downloads\\BigSupplyCo Data Files\\BigSupplyCo Data Files\\BigSupplyCo_Departments.csv'\n",
    "categories_file = r'C:\\Users\\shara\\Downloads\\BigSupplyCo Data Files\\BigSupplyCo Data Files\\BigSupplyCo_Categories.csv'\n",
    "customers_file = r'C:\\Users\\shara\\Downloads\\BigSupplyCo Data Files\\BigSupplyCo Data Files\\BigSupplyCo_Customers.csv'\n",
    "products_file = r'C:\\Users\\shara\\Downloads\\BigSupplyCo Data Files\\BigSupplyCo Data Files\\BigSupplyCo_Products.csv'\n",
    "orders_file = r'C:\\Users\\shara\\Downloads\\BigSupplyCo Data Files\\BigSupplyCo Data Files\\BigSupplyCo_Orders.csv'\n",
    "\n",
    "# Create tables and import data from CSV files\n",
    "create_table_from_csv(departments_file, 'BigSupplyCo_Departments', conn, encoding='ISO-8859-1')\n",
    "create_table_from_csv(categories_file, 'BigSupplyCo_Categories', conn, encoding='ISO-8859-1')\n",
    "create_table_from_csv(customers_file, 'BigSupplyCo_Customers', conn, encoding='ISO-8859-1')\n",
    "create_table_from_csv(products_file, 'BigSupplyCo_Products', conn, encoding='ISO-8859-1')\n",
    "create_table_from_csv(orders_file, 'BigSupplyCo_Orders', conn, encoding='ISO-8859-1')\n",
    "\n",
    "# Commit changes and close the database connection\n",
    "conn.commit()\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Retail Chatbot\")\n",
    "user_input = st.text_input(\"Enter your question:\")\n",
    "show_code = st.checkbox(\"Show Code\")\n",
    "\n",
    "# Main logic\n",
    "if user_input:\n",
    "    try:\n",
    "        # Validate user input (ensure it is not empty or only whitespace)\n",
    "        if user_input.strip() == \"\":\n",
    "            st.warning(\"Please enter a valid question.\")\n",
    "        else:\n",
    "            # Generate AI response based on user input\n",
    "            generated_response, sql_query = generate_ai_response(user_input, tables, columns)\n",
    "\n",
    "            # Show generated AI response\n",
    "            st.subheader(\"AI Response:\")\n",
    "            st.write(generated_response)\n",
    "\n",
    "            # Correct the SQL code based on AI response\n",
    "            corrected_sql_query = sql_query  # You can add logic here to modify the SQL query if needed\n",
    "\n",
    "            # Show SQL code when the \"Show Code\" toggle button is enabled\n",
    "            if show_code:\n",
    "                st.subheader(\"Generated SQL Query:\")\n",
    "                st.code(corrected_sql_query, language='sql')  # Display corrected SQL code as a code block\n",
    "\n",
    "                # Execute SQL query and display result\n",
    "                cur.execute(corrected_sql_query)\n",
    "                result = cur.fetchall()\n",
    "                if result:\n",
    "                    column_names = [description[0] for description in cur.description]\n",
    "                    df = pd.DataFrame(result, columns=column_names)\n",
    "                    st.subheader(\"Query Result:\")\n",
    "                    st.dataframe(df)  # Display DataFrame in Streamlit app\n",
    "                else:\n",
    "                    st.info(\"No results found.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        st.error(f\"Error generating AI response or executing the query: {e}\")\n",
    "\n",
    "# Close Database Connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6a343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
